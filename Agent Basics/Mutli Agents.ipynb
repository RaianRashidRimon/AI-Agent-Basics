{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T18:19:10.383260Z",
     "iopub.status.busy": "2025-11-10T18:19:10.382900Z",
     "iopub.status.idle": "2025-11-10T18:19:10.481152Z",
     "shell.execute_reply": "2025-11-10T18:19:10.480193Z",
     "shell.execute_reply.started": "2025-11-10T18:19:10.383223Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Gemini API key setup complete.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "\n",
    "try:\n",
    "    GOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")\n",
    "    os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n",
    "    os.environ[\"GOOGLE_GENAI_USE_VERTEXAI\"] = \"FALSE\"\n",
    "    print(\"Gemini API key setup complete.\")\n",
    "except Exception as e:\n",
    "    print(f\"Authentication Error: Please make sure you have added 'GOOGLE_API_KEY' to your Kaggle secrets.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T18:19:14.552294Z",
     "iopub.status.busy": "2025-11-10T18:19:14.551622Z",
     "iopub.status.idle": "2025-11-10T18:20:08.041729Z",
     "shell.execute_reply": "2025-11-10T18:20:08.040863Z",
     "shell.execute_reply.started": "2025-11-10T18:19:14.552262Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ ADK components imported successfully.\n"
     ]
    }
   ],
   "source": [
    "# importing component from ADK\n",
    "\n",
    "from google.adk.agents import Agent, SequentialAgent, ParallelAgent, LoopAgent\n",
    "from google.adk.runners import InMemoryRunner\n",
    "from google.adk.tools import AgentTool, FunctionTool, google_search\n",
    "from google.genai import types\n",
    "\n",
    "print(\"ADK components imported successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img width=\"800\" src=\"https://storage.googleapis.com/github-repo/kaggle-5days-ai/day1/multi-agent-team.png\" alt=\"Multi-agent Team\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T16:51:14.196619Z",
     "iopub.status.busy": "2025-11-10T16:51:14.196169Z",
     "iopub.status.idle": "2025-11-10T16:51:14.202475Z",
     "shell.execute_reply": "2025-11-10T16:51:14.201175Z",
     "shell.execute_reply.started": "2025-11-10T16:51:14.196564Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ research_agent created.\n"
     ]
    }
   ],
   "source": [
    "# defining a research agent whose job is to use the google_search tool and present findings.\n",
    "research_agent = Agent(\n",
    "    name=\"ResearchAgent\",\n",
    "    model=\"gemini-2.5-flash-lite\",\n",
    "    instruction=\"\"\"You are a specialized research agent. Your only job is to use the\n",
    "    google_search tool to find 2-3 pieces of relevant information on the given topic and present the findings with citations.\"\"\",\n",
    "    tools=[google_search],\n",
    "    output_key=\"research_findings\", # The result will be stored in the session state with this key.\n",
    ")\n",
    "\n",
    "print(\"research_agent created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T16:51:15.692271Z",
     "iopub.status.busy": "2025-11-10T16:51:15.691923Z",
     "iopub.status.idle": "2025-11-10T16:51:15.697631Z",
     "shell.execute_reply": "2025-11-10T16:51:15.696657Z",
     "shell.execute_reply.started": "2025-11-10T16:51:15.692244Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ summarizer_agent created.\n"
     ]
    }
   ],
   "source": [
    "# another agent, summarizer agent, its job is to summarize the text it receives.\n",
    "summarizer_agent = Agent(\n",
    "    name=\"SummarizerAgent\",\n",
    "    model=\"gemini-2.5-flash-lite\",\n",
    "    # modified instruction to request a bulleted list for a clear output format.\n",
    "    instruction=\"\"\"Read the provided research findings: {research_findings}\n",
    "Create a concise summary as a bulleted list with 3-5 key points.\"\"\",\n",
    "    output_key=\"final_summary\",\n",
    ")\n",
    "\n",
    "print(\"summarizer_agent created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T16:51:17.862850Z",
     "iopub.status.busy": "2025-11-10T16:51:17.862534Z",
     "iopub.status.idle": "2025-11-10T16:51:17.868834Z",
     "shell.execute_reply": "2025-11-10T16:51:17.867839Z",
     "shell.execute_reply.started": "2025-11-10T16:51:17.862825Z"
    },
    "id": "PKthuzRkBtHD",
    "outputId": "dee6d4cc-17b4-4430-8454-d56096fbe360",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ root_agent created.\n"
     ]
    }
   ],
   "source": [
    "# a root coordinator that operates the workflow by calling the sub-agents as tools.\n",
    "root_agent = Agent(\n",
    "    name=\"ResearchCoordinator\",\n",
    "    model=\"gemini-2.5-flash-lite\",\n",
    "    # This instruction tells the root agent HOW to use its tools/ the sub-agents.\n",
    "    instruction=\"\"\"You are a research coordinator. Your goal is to answer the user's query by orchestrating a workflow.\n",
    "1. First, you MUST call the `ResearchAgent` tool to find relevant information on the topic provided by the user.\n",
    "2. Next, after receiving the research findings, you MUST call the `SummarizerAgent` tool to create a concise summary.\n",
    "3. Finally, present the final summary clearly to the user as your response.\"\"\",\n",
    "    # sub-agents are made callable by wraping them as tools as 'AgentTool'\n",
    "    tools=[\n",
    "        AgentTool(research_agent),\n",
    "        AgentTool(summarizer_agent)\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(\"root_agent created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T16:51:20.103221Z",
     "iopub.status.busy": "2025-11-10T16:51:20.102925Z",
     "iopub.status.idle": "2025-11-10T16:51:29.561828Z",
     "shell.execute_reply": "2025-11-10T16:51:29.560656Z",
     "shell.execute_reply.started": "2025-11-10T16:51:20.103197Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ### Created new session: debug_session_id\n",
      "\n",
      "User > What are the latest advancements in LLM transformers and what do they mean for AI?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n",
      "WARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResearchCoordinator > The latest advancements in LLM transformers are centered around their foundational self-attention mechanism, which allows for parallel processing and has dramatically improved AI efficiency and accuracy. This has led to revolutions in Natural Language Processing (NLP) with models like BERT and GPT, and has expanded into computer vision with models like ViT, as well as multimodal AI capable of processing text, images, and audio, exemplified by DALL-E.\n",
      "\n",
      "These advancements have resulted in highly scalable models, and current research is focused on enhancing their ability to handle long-range context and improving overall efficiency. Furthermore, the development of accessible pre-trained and open-weight models is democratizing AI, moving it towards becoming a general-purpose reasoning engine with significant potential across numerous industries.\n"
     ]
    }
   ],
   "source": [
    "runner = InMemoryRunner(agent=root_agent)\n",
    "response = await runner.run_debug(\"What are the latest advancements in LLM transformers and what do they mean for AI?\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
